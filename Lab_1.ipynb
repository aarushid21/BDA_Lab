{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FgVgV7UH-TF4"},"outputs":[],"source":["#1 Write a PySpark program to square set of integers\n","import os\n","import sys\n","import pyspark\n","#from pyspark import SparkContext\n","\n","os.environ['PYSPARK_PYTHON'] = sys.executable\n","os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cudJHF4E-TF6","outputId":"a4028733-4ac9-4165-e609-5ab7f4bc3557"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+\n","|numbers|\n","+-------+\n","|    784|\n","|   7569|\n","|    121|\n","|   7225|\n","|   3969|\n","|      0|\n","|   5184|\n","|   3249|\n","|    900|\n","|    625|\n","+-------+\n","\n"]}],"source":["import random\n","from pyspark.sql import SparkSession\n","\n","sp = SparkSession.builder.config('spark.driver.memory', '16g').appName('square_integers').getOrCreate()\n","nums = random.sample(range(0, 100), 10)\n","#print(nums)\n","f_squared = sp.createDataFrame([(n**2,) for n in nums], ['numbers'])\n","df_squared.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"E-woTsu3-TF7","outputId":"2e7159a3-9c9f-40b9-88cb-ca4126cfad4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["The largest number is:  99\n"]}],"source":["#2 Write a PySpark program to find the maximum of given set of numbers.\n","from pyspark.sql.functions import max as max1\n","\n","ss = SparkSession.builder.appName('find_max').getOrCreate()\n","nums = random.sample(range(0, 100), 10)\n","df_nums = sp.createDataFrame([(n, ) for n in nums], ['random numbers'])\n","#df.agg returns a dataframe and collect[0][0] references the first element of the df\n","max_num = df_nums.agg(max1('random numbers')).collect()[0][0]\n","#print(type(max_num))\n","print(\"The largest number is: \", max_num)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLXUynyb-TF8","outputId":"b21c4e87-e2f5-4e01-bf09-fa0c29f34c8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["The average of the numbers is:  46.1\n"]}],"source":["#3 Write a PySpark program to find average of N numbers.\n","from pyspark.sql.functions import avg\n","\n","ss = SparkSession.builder.appName('find_avg').getOrCreate()\n","nums = random.sample(range(0, 100), 10)\n","df_nums = sp.createDataFrame([(n, ) for n in nums], ['random numbers'])\n","m = df_nums.agg(avg('random numbers')).collect()[0][0]\n","print(\"The average of the numbers is: \", m)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wcjQJGqP-TF8","outputId":"03f1c4e4-4c7d-4562-957b-4a44458edd81"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----+-----+-----+-----+\n","|days|weeks|years|names|\n","+----+-----+-----+-----+\n","|   1|    5|    0|   aa|\n","|   2|    6|    0|   bb|\n","|   3|    4|    0|   ab|\n","|   4|    3|    0|   ba|\n","|   5|    8|    0|   cc|\n","|   6|    9|    0|   dd|\n","+----+-----+-----+-----+\n","\n","root\n"," |-- days: integer (nullable = true)\n"," |-- weeks: integer (nullable = true)\n"," |-- years: integer (nullable = true)\n"," |-- names: string (nullable = true)\n","\n"]}],"source":["#4 Demonstrate how to read a CSV file into a PySpark DataFrame.\n","#5 Use PySpark commands to display the first few rows and schema of a DataFrame.\n","ss = SparkSession.builder.appName('get_csv').getOrCreate()\n","df = ss.read.csv('trial.csv', header = True, inferSchema = True)\n","df.show()\n","df.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7LROw9-3-TF8","outputId":"265db628-5d25-42bd-b999-e36e66e6305d"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+------------------+\n","|summary|             weeks|\n","+-------+------------------+\n","|  count|                 6|\n","|    min|                 3|\n","|    max|                 9|\n","|   mean| 5.833333333333333|\n","| stddev|2.3166067138525404|\n","+-------+------------------+\n","\n"]}],"source":["#6 Calculate basic summary statistics for a specific column in the DataFrame.\n","weeks = df.select(\"weeks\").summary(\"count\", \"min\", \"max\", \"mean\", \"stddev\")\n","weeks.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mWJSI8w-TF9"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}